{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824dbb03-7d43-4ee6-bdde-be5c0a3962ba",
   "metadata": {},
   "source": [
    "# TB2J optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf4044-999c-4773-9be8-ee2352dbaba3",
   "metadata": {},
   "source": [
    "This notebook contains prototype vectorized routines for TB2J. They focus on computing the $A^{uv}_{ij}$ tensor and the real-space Green's function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13190ff1-5768-4863-b540-54b96df08671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from TB2J.exchange import ExchangeNCL\n",
    "from HamiltonIO.siesta import SislParser\n",
    "from TB2J.pauli import pauli_block_all\n",
    "\n",
    "def vec_pauli_block(array):\n",
    "\n",
    "    A00 = array[..., ::2, ::2]\n",
    "    A01 = array[..., ::2, 1::2]\n",
    "    A10 = array[..., 1::2, ::2]\n",
    "    A11 = array[..., 1::2, 1::2]\n",
    "    n2 = array.shape[-1] // 2\n",
    "\n",
    "    out_dtype = np.result_type(array.dtype, np.complex64)\n",
    "    block = np.empty((*array.shape[:-2], 4, n2, n2), dtype=out_dtype)\n",
    "\n",
    "    np.add(A00, A11, out=block[..., 0, :, :]); block[..., 0, :, :] *= 0.5\n",
    "    np.add(A01, A10, out=block[..., 1, :, :]); block[..., 1, :, :] *= 0.5\n",
    "    np.subtract(A01, A10, out=block[..., 2, :, :]); block[..., 2, :, :] *= 0.5j\n",
    "    np.subtract(A00, A11, out=block[..., 3, :, :]); block[..., 3, :, :] *= 0.5\n",
    "\n",
    "    return block\n",
    "\n",
    "def vec_pauli_sigma_norm(array):\n",
    "\n",
    "    block = vec_pauli_block(array)[..., 1:, :, :]\n",
    "    E = np.trace(block, axis1=-2, axis2=-1)\n",
    "    E /= np.linalg.norm(E, axis=-1, keepdims=True)\n",
    "    np.multiply(block, E[..., None, None], out=block)\n",
    "\n",
    "    return block.sum(axis=-3)\n",
    "\n",
    "def compute_GR(exchangencl, Gk):\n",
    "\n",
    "    Rvecs = np.array(exchangencl.short_Rlist)\n",
    "    kpts = exchangencl.G.kpts\n",
    "    phase = np.exp(exchangencl.G.k2Rfactor * np.einsum('ni,mi->nm', Rvecs, kpts))\n",
    "    phase *= exchangencl.G.kweights[None]\n",
    "    GR = np.einsum('kij,rk->rij', Gk, phase, optimize='optimal')\n",
    "\n",
    "    return GR\n",
    "\n",
    "def compute_A_all(exchangencl, energy):\n",
    "\n",
    "    Gk = exchangencl.G.get_Gk_all(energy)\n",
    "    GR = compute_GR(exchangencl, Gk)\n",
    "\n",
    "    magnetic_sites = exchangencl.ind_mag_atoms\n",
    "    iorbs = [exchangencl.iorb(site) for site in magnetic_sites]\n",
    "    P = [vec_pauli_sigma_norm(\n",
    "        np.take(np.take(exchangencl.HR0, idx, axis=-2), idx, axis=-1)\n",
    "    )\n",
    "        for idx in iorbs\n",
    "    ]\n",
    "\n",
    "    A = {}\n",
    "    for i, j in product(range(len(magnetic_sites)), repeat=2):\n",
    "        idx, jdx = iorbs[i], iorbs[j]\n",
    "        Gij = GR[:, idx][:, :, jdx]\n",
    "        Gji = GR[:, jdx][:, :, idx]\n",
    "        Gij = vec_pauli_block(Gij)\n",
    "        Gji = vec_pauli_block(Gji)\n",
    "        Gji = np.flip(Gji, axis=0)\n",
    "        Pi = P[i]\n",
    "        Pj = P[j]\n",
    "        X = Pi @ Gij\n",
    "        Y = Pj @ Gji\n",
    "        mi, mj = (magnetic_sites[i], magnetic_sites[j])\n",
    "        A[mi, mj] = np.einsum('...uij,...vji->...uv', X, Y) / np.pi\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef5fb1c-cbf5-4b69-bbeb-b2823e4df9cf",
   "metadata": {},
   "source": [
    "We vectorize about interaction vectors, kpoints, and $A^{uv}_{ij}$ components. It reduces the number of function calls and gets rid of unnecessary loops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224556d-a7f7-49f5-8a94-ebd8e4634f49",
   "metadata": {},
   "source": [
    "Let's see how these routines compare to the master version of TB2J. To do this, we select a moderate kmesh of $7 \\times 7 \\times 7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e95061d-2203-44f1-812d-2d47dbd44b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A gap is found at -22.473318471821468, set emin to it.\n",
      "Magnetic atoms: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "parser = SislParser(\n",
    "    fdf_fname='siesta.fdf', ispin=None, read_H_soc=False, orth=False\n",
    ")\n",
    "model = parser.get_model()\n",
    "basis = dict(zip(model.orbs, list(range(model.nbasis))))\n",
    "exargs = dict(\n",
    "    magnetic_elements=['Co'],\n",
    "    include_orbs=None,\n",
    "    kmesh=[7, 7, 7],\n",
    "    emin=-12.0,\n",
    "    emax=0.0,\n",
    "    nz=100,\n",
    "    exclude_orbs=[],\n",
    "    Rcut=None,\n",
    "    ne=None,\n",
    "    nproc=1,\n",
    "    use_cache=False,\n",
    "    output_path=\"TB2J_results\",\n",
    "    orb_decomposition=False,\n",
    "    orth=False,\n",
    "    ibz=False,\n",
    "    description=\"\",\n",
    ")\n",
    "exchangencl = ExchangeNCL(\n",
    "    tbmodels=model,\n",
    "    atoms=model.atoms,\n",
    "    basis=basis,\n",
    "    efermi=0.0,\n",
    "    **exargs\n",
    ")\n",
    "energies = exchangencl.contour.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28a12d-4a88-4f64-9fce-06a046099d87",
   "metadata": {},
   "source": [
    "We now compare the performance of both approaches. First, the $A^{uv}_{ij}$ tensor can be calculated with TB2J as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b03bfd55-deae-49c1-9355-7962924124d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB2J took 28.392 seconds to complete.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "A_dict = exchangencl.get_quantities_per_e(energies[50])\n",
    "end_time = time()\n",
    "regular_time1 = end_time - start_time\n",
    "print(f\"TB2J took {regular_time1:.3f} seconds to complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ecd315-5463-4199-9961-c5401d73915f",
   "metadata": {},
   "source": [
    "With the vectorized routines the $A^{uv}_{ij}$ tensor is calculated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba165d67-ded2-4f2e-a67f-a2cbd11f3e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized TB2J took 3.454 seconds to complete. A 87.84% time reduction!\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "A_vec_dict = compute_A_all(exchangencl, energies[50])\n",
    "end_time = time()\n",
    "regular_time2 = end_time - start_time\n",
    "print(f\"Vectorized TB2J took {regular_time2:.3f} seconds to complete. A {(regular_time1 - regular_time2) / regular_time1 * 100:.2f}% time reduction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be9bcf-2bf5-418a-bfe3-556ad3cc503c",
   "metadata": {},
   "source": [
    "The last step is do a sanity check to make sure that the vectorized routines give the same results as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d72fdba-0880-4a35-8f17-8d491c56c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No assertion errors found, meaning that we obtain the same tensor as before.\n"
     ]
    }
   ],
   "source": [
    "for pair, Atensor in A_vec_dict.items():\n",
    "    assert all(np.allclose(Atensor[i], A_dict['AijR'][Rm, *pair]) for i, Rm in enumerate(exchangencl.short_Rlist))\n",
    "print('No assertion errors found, meaning that we obtain the same tensor as before.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
